---
title: "8105 HW6"
output: github_document
date: '2022-12-3'
---

```{r}
# load libraries
library(tidyverse)
library(rvest)
library(httr)
library(purrr)
library(patchwork)
library(viridis)
library(modelr)
library(mgcv)
```

# Problem 1
```{r}
# data manipulation
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

# Problem 2
```{r}
# import the data 
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide_df = read_csv(url) %>% 
  janitor::clean_names()
```

```{r}
# tidy it according to the requirements
# resolved = 1, unresolved = 0
homicide_df = 
  homicide_df %>% 
  mutate(
    city_state = paste(city, state, sep = ","),
    disposition = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age),
    victim_race = fct(victim_race)
  ) %>% 
  filter(city_state != "Dallas,TX" & city_state != "Phoenix,AZ" & city_state != "Kansas City,MO" & city_state != "Tulsa,AL") %>% 
  filter(victim_race == "White" | victim_race == "Black")
```

```{r}
homicide_summary_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  select(city_state, disposition, victim_age, victim_sex, victim_race)
```

```{r}
# Baltimore,MD
Baltimore_df = 
  homicide_summary_df %>% 
  filter(city_state == "Baltimore,MD") 
  
 
test_Baltimore = 
  glm(disposition ~ victim_age + victim_sex + victim_race, data = Baltimore_df, family = binomial()) %>%
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower_bound = exp(estimate - 1.96 * std.error),
    CI_upper_bound = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, estimate, OR, CI_lower_bound, CI_upper_bound) %>% 
  knitr::kable(digits = 4)
test_Baltimore

```

```{r}
# all other cities' data
cities_stats = 
  homicide_summary_df %>% 
  nest(reg_data = -city_state) %>% 
  mutate(
    reg_line = map(.x = reg_data, ~glm(disposition ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    reg_line = map(reg_line, broom::tidy)
  ) %>% 
  select(-reg_data) %>% 
  unnest(reg_line) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    OR = exp(estimate),
    CI_lower_bound = exp(estimate - 1.96 * std.error),
    CI_upper_bound = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, OR, CI_lower_bound, CI_upper_bound)

# making a plot
OR_plot =
  cities_stats %>% 
  ggplot(aes(x = fct_reorder(city_state, OR), y = OR)) + geom_point() + geom_errorbar(aes(ymin = CI_lower_bound, ymax = CI_upper_bound)) +
  labs(title = "OR for solving homicides comparing male to female", x = "City/State", y = "OR") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.9, hjust = 1)) +
  theme(plot.title = element_text(hjust = 0.5)) 

OR_plot
```
comment of the OR plot:
New York has the lowest estimated OR and Albuquerque has the highest estimated OR and it also has the widest confidence interval. Some cities like San Bemardino has lower OR than some other cities but it has wider associated confidence interval.

# Problem 3
```{r}
# data manipulation, check for any missing values
birth_df =
  read_csv("birthweight.csv") %>% 
  janitor::clean_names() %>% 
  select(bwt, everything()) %>% 
  drop_na()
```
comment: The size of the birthweight dataset doesn't change before and after dropping the NAs, so there is no missing value in the dataset.

```{r}
# convert numeric to factor where appropriate
birth_df %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    parity = as.factor(parity),
    pnumlbw = as.factor(pnumlbw),
    pnumsga = as.factor(pnumsga)
  )
```

```{r}
# model building
# 1st step: put all variables into the model to check the possible coefficients
model_check = 
  lm(bwt ~ ., data = birth_df) %>% 
  broom::tidy()

model_check
```
comment: variables "pnumlbw", "pnumsga", "wtgain" have no estimate, so we rule them out from the original model and build another model without them.

```{r}
# find the "best" model 
model_check_update =
  lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + ppbmi + ppwt + smoken, data = birth_df)

model_check_update %>% 
  broom::tidy()
```

```{r}
# find the "best" model continued...
model_final =
  lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + momage + mrace + parity + smoken, data = birth_df)

model_final %>% 
  broom::tidy()
```
modeling process description: In order to find the "optimal" model, I first put all variables into the model and find their estimates and p-values. Then, there are some covariates that has NA estimates which are ruled out from the model. Next, build a model with covariates that have actual estimates values, but there are some covariates whose p-values are greater that 0.05 which are also excluded from the final model. Finally, make a model again excluding those covariates(NA estimates and big p-values).

```{r}
# add predictions and residuals to the model_check_update
birth_df %>% 
  add_residuals(model_final) %>% 
  add_predictions(model_final) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.2) +
  geom_line(aes(y = 0), color = "red") +
  labs(
    title = "Fitted Values vs Residuals Based on the Built Model",
    x = "Fitted Values",
    y = "Residuals"
    ) +
  theme(plot.title = element_text(hjust = 0.5))
```
comment: the residuals are basically symmetric around y=0, and centered around the "y=0" line which makes sense.
  
```{r}
# first comparison model
model1 = lm(bwt ~ blength + gaweeks, data = birth_df) %>% 
  broom::tidy()
model1
```

```{r}
# second comparison model
model2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birth_df) %>% 
  broom::tidy()
model2
```

```{r}
# comparison models
compare_models = 
  crossv_mc(birth_df,100) %>% 
  mutate(
    train = map(train,as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    model1_train = map(train, ~lm(bwt ~ blength + gaweeks, data = birth_df)),
    model2_train = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birth_df)),
    model_final_train = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + momage + mrace + parity + smoken, data = birth_df))
  ) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1_train, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2_train,  test, ~rmse(model = .x, data = .y)),
    rmse_model_final = map2_dbl(model_final_train, test, ~rmse(model = .x, data = .y)),
  )
```

```{r}
# draw a violin plot to compare three models (some code from lecture)
compare_models %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(
    model = fct_inorder(model)
  ) %>% 
  ggplot(aes(x = model, y = rmse, color = model)) + 
  geom_violin()+
  labs(
    x = "Three Different Models",
    y = "rmse",
    title = "Comparison of Three Models"
  )+
  theme(plot.title = element_text(hjust = .5))
```
comment: According to the violin plot, model1 (with "length at birth" and "gestational age" as predictors) has the highest rmse, the one I built (with "babysex", "bhead", "blength", "delwt", "fincome", "gaweeks", "momage", "mrace", "parity", "smoken" as predictors) has the lowest rmse, and model2 (with "head circumference", "length", "sex" and their interaction as predictors) has the second highest rmse. So the efficiency rank of three models (from highest to lowest) is : my model, model 2 and model1.





